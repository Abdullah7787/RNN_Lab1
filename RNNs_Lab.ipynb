{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbfec32-1b50-43e9-a648-c9879dc4b79c",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1eb792b-8cfc-44d8-9d1c-0bf8c403fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7705c2-42a1-4047-bbac-3a0f7465e032",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31467209-c5d3-4a4f-a79f-4a2f6e68ce85",
   "metadata": {},
   "source": [
    "### Load Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ef01310-47d6-44ac-aff1-abf4da07a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, train_labels = [], []\n",
    "\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/pos/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d463c-377c-4730-9398-cb5fcaa5e44b",
   "metadata": {},
   "source": [
    "### Load Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "937bb606-b07a-4e7e-a83a-1ccce2b18263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the txt file negative tweet\n",
    "neg = os.getcwd() + '/corpus/arabic_tweets/neg/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(neg):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(neg, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e8e33-f28b-4402-ab6d-f4925c1db165",
   "metadata": {},
   "source": [
    "### Build a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "743b5741-d234-4d22-a833-76ec742cd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>دامك مع #غناتي ، فالك طيب 👍\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>على الفطرة السليمه.. الله يعطيه الصحة والعافية...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets    Labels\n",
       "0                      دامك مع #غناتي ، فالك طيب 👍\\n  positive\n",
       "1  على الفطرة السليمه.. الله يعطيه الصحة والعافية...  positive\n",
       "2        📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n  positive\n",
       "3  سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...  positive\n",
       "4        مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n  positive"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dic = {\n",
    "    'Tweets' : train_tweets,\n",
    "    'Labels' : train_labels\n",
    "}\n",
    "\n",
    "train_corpus = pd.DataFrame(train_dic)\n",
    "train_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046ada-13fc-45d2-9056-b4115de8e812",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "##### Explore your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b6d563b-a771-43b4-8e43-3688275b1f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>دامك مع #غناتي ، فالك طيب 👍\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>على الفطرة السليمه.. الله يعطيه الصحة والعافية...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58746</th>\n",
       "      <td>تو اتابع الملخص اياكس شيء عظيم يخوان والله افت...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58747</th>\n",
       "      <td>يوم كامل وفقط أضفت فقرتين 😑\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58748</th>\n",
       "      <td>ما رح اتخلى عنك ❤ حتى لو بدي ازعل واتوجع منك 💔...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>والله عيب .. البعض يحتاج سنوات ضوئية .. حتى يت...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58750</th>\n",
       "      <td>عذر اقبح من ذنب 🤔\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58751 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels\n",
       "0                          دامك مع #غناتي ، فالك طيب 👍\\n  positive\n",
       "1      على الفطرة السليمه.. الله يعطيه الصحة والعافية...  positive\n",
       "2            📷 مشجع هلالي ينبذ العنصرية ب لافته أعدها.\\n  positive\n",
       "3      سبحان الله🌸 الحمدلله 💮 لا اله الا الله 🌿 الله ...  positive\n",
       "4            مشاركتي في مبادراتكم الجميلة فوز وسعادة 💞\\n  positive\n",
       "...                                                  ...       ...\n",
       "58746  تو اتابع الملخص اياكس شيء عظيم يخوان والله افت...  negative\n",
       "58747                      يوم كامل وفقط أضفت فقرتين 😑\\n  negative\n",
       "58748  ما رح اتخلى عنك ❤ حتى لو بدي ازعل واتوجع منك 💔...  negative\n",
       "58749  والله عيب .. البعض يحتاج سنوات ضوئية .. حتى يت...  negative\n",
       "58750                                عذر اقبح من ذنب 🤔\\n  negative\n",
       "\n",
       "[58751 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8d4a6-89a4-47b1-bf43-08dc09b97506",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8d9fa-6fb7-4352-aadb-3abeb932c412",
   "metadata": {},
   "source": [
    "### Shuffle all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "246bb815-274b-43a3-9d60-967a5864a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train_corpus.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1a323e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مررت بكل ذلك وحدي ،، فلا تخبرني اننا أصدقاء 💔\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.♥ . ♥. ♥ صباح ♥ ♥الذاكرين♥ .♥ . ♥. أسأل الله ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بعين الله 😳 ازا الاجازة ما كانت يومين ما بتتسم...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>🏆 تتويج بطلا للدوري 🔻 هبوط الباطن والتسامح ⚽️ ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نختلف فى الميول ونختلف فى الأفكار ونختلف في أش...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58746</th>\n",
       "      <td>🌸 طوينا الكثير من الصفحات في حياتنا لأننا أنتھ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58747</th>\n",
       "      <td>سبحان الله وبحمده سبحان الله العظيم ارح مسمعك 😴\\n</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58748</th>\n",
       "      <td>ماعندي خبر 💔 بس قد صارتلي نفس المشكلة وانا موب...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58750</th>\n",
       "      <td>#الوطن_لايشرفه_الفاسدين كيس الشعلان تتهمنا بال...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58751 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels\n",
       "0        مررت بكل ذلك وحدي ،، فلا تخبرني اننا أصدقاء 💔\\n  negative\n",
       "1      .♥ . ♥. ♥ صباح ♥ ♥الذاكرين♥ .♥ . ♥. أسأل الله ...  positive\n",
       "2      بعين الله 😳 ازا الاجازة ما كانت يومين ما بتتسم...  negative\n",
       "3      🏆 تتويج بطلا للدوري 🔻 هبوط الباطن والتسامح ⚽️ ...  positive\n",
       "4      نختلف فى الميول ونختلف فى الأفكار ونختلف في أش...  positive\n",
       "...                                                  ...       ...\n",
       "58746  🌸 طوينا الكثير من الصفحات في حياتنا لأننا أنتھ...  positive\n",
       "58747  سبحان الله وبحمده سبحان الله العظيم ارح مسمعك 😴\\n  negative\n",
       "58748  ماعندي خبر 💔 بس قد صارتلي نفس المشكلة وانا موب...  negative\n",
       "58749  بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...  positive\n",
       "58750  #الوطن_لايشرفه_الفاسدين كيس الشعلان تتهمنا بال...  negative\n",
       "\n",
       "[58751 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10a499-afa6-4d35-aa8a-53dbcae8e557",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "**Hint: remove URLs, Hashtags, alphanumeric characters, punctuation marks, stop words, extra spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d141959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "hashtag_pattern = r\"#\\w+\"\n",
    "mention_pattern = r\"@\\w+\"\n",
    "alphanumeric_pattern = r\"\\w*\\d\\w*\"\n",
    "punctuation_pattern = r\"[^\\w\\s]\"\n",
    "retweet_pattern = r\"^RT[\\s]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "957b0161-4c2d-4f33-90a3-e8892a27455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "    return frozenset(stop_set)\n",
    "\n",
    "def process_text(text, stop_words):\n",
    "    # Remove URLs\n",
    "    text = re.sub(URL_pattern, '', text)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(hashtag_pattern, '', text)\n",
    "    \n",
    "    # Remove mention\n",
    "    text = re.sub(mention_pattern, '', text)\n",
    "\n",
    "    # Remove alphanumeric characters\n",
    "    text = re.sub(alphanumeric_pattern, '', text)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(punctuation_pattern, '', text)\n",
    "    \n",
    "    # Remove Retweet marks\n",
    "    text = re.sub(retweet_pattern, '', text)\n",
    "\n",
    "    # Remove stop words using the provided set\n",
    "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5996172",
   "metadata": {},
   "source": [
    "#### Now Clean your text using above function or implement it from scrach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aba473d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = load_stopwords('corpus/Stop_Words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbae5f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_corpus.shape[0]):\n",
    "    train_corpus.loc[i,'Tweets'] = process_text(train_corpus.loc[i,'Tweets'],stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56909fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>مررت بكل وحدي فلا تخبرني اننا أصدقاء</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الذاكرين أسأل الله أن يبشرك بما يسرك ويكف عنك ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بعين الله ازا الاجازة يومين بتتسمى اجازة</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>تتويج بطلا للدوري هبوط الباطن والتسامح تقرير خ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نختلف الميول ونختلف الأفكار ونختلف أشياء كثيرا</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58746</th>\n",
       "      <td>طوينا الكثير الصفحات حياتنا لأننا أنتھينا قراء...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58747</th>\n",
       "      <td>سبحان الله وبحمده سبحان الله العظيم ارح مسمعك</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58748</th>\n",
       "      <td>ماعندي خبر بس صارتلي نفس المشكلة وانا موبايلي ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58749</th>\n",
       "      <td>بمناسبة فوز الهلال سحب آيفون XR رتويت وتابع ال...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58750</th>\n",
       "      <td>كيس الشعلان تتهمنا بالعنصرية</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58751 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets    Labels\n",
       "0                   مررت بكل وحدي فلا تخبرني اننا أصدقاء  negative\n",
       "1      الذاكرين أسأل الله أن يبشرك بما يسرك ويكف عنك ...  positive\n",
       "2               بعين الله ازا الاجازة يومين بتتسمى اجازة  negative\n",
       "3      تتويج بطلا للدوري هبوط الباطن والتسامح تقرير خ...  positive\n",
       "4         نختلف الميول ونختلف الأفكار ونختلف أشياء كثيرا  positive\n",
       "...                                                  ...       ...\n",
       "58746  طوينا الكثير الصفحات حياتنا لأننا أنتھينا قراء...  positive\n",
       "58747      سبحان الله وبحمده سبحان الله العظيم ارح مسمعك  negative\n",
       "58748  ماعندي خبر بس صارتلي نفس المشكلة وانا موبايلي ...  negative\n",
       "58749  بمناسبة فوز الهلال سحب آيفون XR رتويت وتابع ال...  positive\n",
       "58750                       كيس الشعلان تتهمنا بالعنصرية  negative\n",
       "\n",
       "[58751 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus.reset_index(inplace=True,drop=True)\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0cb63",
   "metadata": {},
   "source": [
    "#### Extra: you could do stemming or lemmatization before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485120c-47f1-43e9-b6c1-cbe0a69f04c7",
   "metadata": {},
   "source": [
    "# Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6810fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8 \n",
    "split_index = int(split_ratio * len(train_corpus))\n",
    "x_train, y_train = train_corpus.loc[:split_index,'Tweets'], train_corpus.loc[:split_index,'Labels']\n",
    "x_test, y_test = train_corpus.loc[split_index:,'Tweets'], train_corpus.loc[split_index:,'Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a828691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47000                                 جزاك الله احسن الجزا\n",
       "47001    هه طظ الدنيا ياجدع والنعمه انت رايق ولافارق مع...\n",
       "47002                                                انشهد\n",
       "47003    بمناسبة فوز الهلال سحب آيفون XR رتويت وتابع ال...\n",
       "47004                     الحمدالله السلامة ابو عبد المحسن\n",
       "                               ...                        \n",
       "58746    طوينا الكثير الصفحات حياتنا لأننا أنتھينا قراء...\n",
       "58747        سبحان الله وبحمده سبحان الله العظيم ارح مسمعك\n",
       "58748    ماعندي خبر بس صارتلي نفس المشكلة وانا موبايلي ...\n",
       "58749    بمناسبة فوز الهلال سحب آيفون XR رتويت وتابع ال...\n",
       "58750                         كيس الشعلان تتهمنا بالعنصرية\n",
       "Name: Tweets, Length: 11751, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160549cf-bffd-4205-a8fa-a6aa0695bcd8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f152bfd-478f-4cdd-b17e-885d4649019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(oov_token='<OOV>')\n",
    "token.fit_on_texts(x_train)\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba90d2-7712-4e80-9120-c82f495b5f66",
   "metadata": {},
   "source": [
    "# Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b035311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequ = token.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f98fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21c31c7d-0375-4ef2-9f51-dccef70793d3",
   "metadata": {},
   "source": [
    "# Pad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1807aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequ = max(len(seq) for seq in sequ)\n",
    "paded = pad_sequences(sequ,maxlen=max_sequ,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d05e3c6-6f92-4a49-a904-f0af742ffe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0909-8e90-4aef-9ddb-42c3597791cb",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47efb8b2-7635-48ba-a4ae-4118862e74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(token.word_index) + 1, output_dim=100, input_length=max_sequ))\n",
    "model.add(SimpleRNN(units=100))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6adb57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f097ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 9s 23ms/step - loss: 0.4970 - accuracy: 0.7213\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 9s 23ms/step - loss: 0.1573 - accuracy: 0.9362\n",
      "Epoch 3/10\n",
      "368/368 [==============================] - 10s 26ms/step - loss: 0.0731 - accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "368/368 [==============================] - 9s 24ms/step - loss: 0.0564 - accuracy: 0.9769\n",
      "Epoch 5/10\n",
      "368/368 [==============================] - 9s 24ms/step - loss: 0.0481 - accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "368/368 [==============================] - 8s 23ms/step - loss: 0.0434 - accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "368/368 [==============================] - 8s 23ms/step - loss: 0.0424 - accuracy: 0.9803\n",
      "Epoch 8/10\n",
      "368/368 [==============================] - 9s 24ms/step - loss: 0.0394 - accuracy: 0.9824\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 10s 28ms/step - loss: 0.0387 - accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 8s 23ms/step - loss: 0.0367 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29087df10>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(paded,y_train, epochs=10 ,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a35492-747b-4fea-a80c-1602ff36da21",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dea5fb34-e15c-45cf-bf39-5a4c65a28705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=len(token.word_index) + 1, output_dim=100, input_length=max_sequ))\n",
    "model1.add(LSTM(units=100))\n",
    "model1.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b87361da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d168be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 15s 40ms/step - loss: 0.5092 - accuracy: 0.7211\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 15s 41ms/step - loss: 0.2636 - accuracy: 0.8859\n",
      "Epoch 3/10\n",
      "368/368 [==============================] - 15s 41ms/step - loss: 0.1366 - accuracy: 0.9448\n",
      "Epoch 4/10\n",
      "368/368 [==============================] - 15s 41ms/step - loss: 0.0926 - accuracy: 0.9616\n",
      "Epoch 5/10\n",
      "368/368 [==============================] - 15s 41ms/step - loss: 0.0751 - accuracy: 0.9668\n",
      "Epoch 6/10\n",
      "368/368 [==============================] - 15s 42ms/step - loss: 0.0639 - accuracy: 0.9689\n",
      "Epoch 7/10\n",
      "368/368 [==============================] - 17s 46ms/step - loss: 0.0604 - accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "368/368 [==============================] - 16s 42ms/step - loss: 0.0559 - accuracy: 0.9733\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 16s 42ms/step - loss: 0.0504 - accuracy: 0.9745\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 15s 41ms/step - loss: 0.0488 - accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a1037310>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(paded,y_train, epochs=10 ,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e105a33-8de7-406f-a5fb-c1a558c7bb9d",
   "metadata": {},
   "source": [
    "# Evaulation and Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a956b35-0604-44d5-87f2-eacfb36870d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(oov_token='<OOV>')\n",
    "token.fit_on_texts(x_test)\n",
    "word_index = token.word_index\n",
    "\n",
    "sequ = token.texts_to_sequences(x_test)\n",
    "\n",
    "paded = pad_sequences(sequ,maxlen=max_sequ,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1a0ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a92b02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 1s 1ms/step - loss: 1.4607 - accuracy: 0.4971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4607253074645996, 0.49706408381462097]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=paded,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61ff14f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368/368 [==============================] - 1s 3ms/step - loss: 3.0862 - accuracy: 0.5226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0861785411834717, 0.5225937962532043]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(paded,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
